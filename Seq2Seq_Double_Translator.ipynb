{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnBBpiayq8pT"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input,SpatialDropout1D\n",
        "from tensorflow.keras.optimizers import RMSprop, Adadelta\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuC4BWgWgOX8",
        "outputId": "e93e0379-6b54-4cf3-fa14-9f5fa42c9cad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive  #connect the Google drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data loading and processing"
      ],
      "metadata": {
        "id": "icydaeUxjQ5u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlWQSTWur6h3",
        "outputId": "af53191a-1fc0-44a0-e3f0-4f2604a82181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-15 13:44:45--  http://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 172.67.186.54, 104.21.92.44, 2606:4700:3033::ac43:ba36, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|172.67.186.54|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14683939 (14M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]  14.00M  48.6MB/s    in 0.3s    \n",
            "\n",
            "2022-03-15 13:44:45 (48.6 MB/s) - ‘rus-eng.zip’ saved [14683939/14683939]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://www.manythings.org/anki/rus-eng.zip  #скачиваем dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vYnT5s_sAZw",
        "outputId": "23e0293f-5045-41ef-da0f-6ff7fe2ab0ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  rus-eng.zip  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls  #проверям список файлов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j26-tpHysJhG",
        "outputId": "f8a42179-f339-4f26-b151-13c4b3d59591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ],
      "source": [
        "!unzip -o rus-eng.zip #распаковка архива"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHrmsoqxsZe-"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open('rus.txt', 'r', encoding='utf-8') as f:\n",
        "  lines=f.read().split('\\n') #разибваем файл на строки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml3non8us7RQ",
        "outputId": "6aa5c4fc-a3da-4f81-de6b-f94e5bff392d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "440220"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y5rq9hHbtLgw",
        "outputId": "3af69a10-f453-4efd-d9e4-d0b5ef631928"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Go.\\tМарш!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1159202 (shanghainese)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "lines[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ht6fSl1StFXz"
      },
      "outputs": [],
      "source": [
        "def extract_texts(begin_index=0, qty=50000):\n",
        "  conversations=[]\n",
        "  \n",
        "  lenLines=len(lines)\n",
        "  #if begin_index is beyond of lines number\n",
        "  if begin_index>=lenLines:\n",
        "    return None\n",
        "  #calculation of end_index\n",
        "  end_index=begin_index+qty\n",
        "  if end_index >= lenLines:\n",
        "    end_index = lenLines         #if end_index is beyond of lines number\n",
        "\n",
        "  for i in range(begin_index,end_index):\n",
        "    try:\n",
        "      eng_text, rus_text,_ = lines[i].split('\\t') #разделяем линии на русские и англ сообщения\n",
        "      conversations.append([eng_text,rus_text])\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "  return conversations "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1HXOw2-hjCP"
      },
      "outputs": [],
      "source": [
        "conversations=extract_texts(qty=100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGc4dwsbhqHO",
        "outputId": "ec6e1dcd-f2de-4981-fc79-0422abeb154b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(conversations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DU_7YmVKtlO9"
      },
      "outputs": [],
      "source": [
        "#функция для удаления пробелов перед знаками препинания\n",
        "def replacer(inputs):\n",
        "  \n",
        "  if isinstance(inputs,str):\n",
        "      return inputs.replace(' .','.').replace(' ,',',').replace(' !','!').replace(' ?','?')\n",
        "\n",
        "  if isinstance(inputs, list):\n",
        "    outputs=[]\n",
        "\n",
        "    for line in inputs:\n",
        "      outputs.append(line.replace(' .','.').replace(' ,',',').replace(' !','!').replace(' ?','?'))\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keS4Fz5uuxy4"
      },
      "outputs": [],
      "source": [
        "#списки для переводчика eng-rus\n",
        "eng_questions=[] \n",
        "rus_answers=[]\n",
        "\n",
        "#списки для переводчика rus-eng\n",
        "rus_questions=[] \n",
        "eng_answers=[]\n",
        "\n",
        "for con in conversations:\n",
        "  if len(con)>1:\n",
        "    eng=replacer(con[0]) #чистим англю предложения\n",
        "    eng_questions.append(eng)\n",
        "    eng_answers.append(eng)\n",
        "\n",
        "    rus=replacer(con[1:]) #чистим русские предложения\n",
        "    rus=' '.join(rus)\n",
        "    rus_questions.append(rus)\n",
        "    rus_answers.append(rus)\n",
        "\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "#добавляем тэги к ответам  \n",
        "eng_answers=['<START> ' + answ + ' <END>' for answ in eng_answers]  \n",
        "rus_answers=['<START> ' + answ + ' <END>' for answ in rus_answers]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCtFRnJzxk-B",
        "outputId": "6d8464b8-33f7-4072-bf8c-8490625ccbb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фрагмент словаря : [('start', 1), ('end', 2), ('я', 3), ('i', 4), ('tom', 5), ('не', 6), ('том', 7), ('you', 8), ('это', 9), ('is', 10), ('a', 11), ('ты', 12), ('to', 13), ('the', 14), ('вы', 15), (\"i'm\", 16), ('мне', 17), ('мы', 18), ('do', 19), ('it', 20), ('was', 21), ('у', 22), ('we', 23), ('в', 24), ('что', 25), (\"don't\", 26), ('он', 27), ('my', 28), ('are', 29), ('your', 30)]\n",
            "Размер словаря : 41881\n"
          ]
        }
      ],
      "source": [
        "#Создадим токенайзер\n",
        "tokenizer=Tokenizer(filters='\"#$%&()*+-/;<=>@[\\\\]^_`{|}~\\t\\n',split=' ')\n",
        "\n",
        "#обучение токенайзера\n",
        "tokenizer.fit_on_texts(eng_questions+rus_answers)\n",
        "\n",
        "vocabularyItems=list(tokenizer.word_index.items())\n",
        "vocabularySize=len(vocabularyItems)+1\n",
        "\n",
        "print('Фрагмент словаря : {}'.format(vocabularyItems[:30]))\n",
        "print('Размер словаря : {}'.format(vocabularySize))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcKEbGVIVrJh"
      },
      "outputs": [],
      "source": [
        "#Fuction makes tokens sequence from phrase\n",
        "def strToTokens(sentence, maxLen):\n",
        "  #clear extra spaces\n",
        "  tmp_sent=replacer(sentence)\n",
        "\n",
        "  #convert the sentece to lower case and divide to words\n",
        "  words=tmp_sent.lower().split()\n",
        "\n",
        "  #list for tokens\n",
        "  tokensList=list()\n",
        "\n",
        "  for word in words:\n",
        "\n",
        "    try:\n",
        "      tokensList.append(tokenizer.word_index[word]) #try to get a token for a word\n",
        "    \n",
        "    except:\n",
        "      pass  #or just ignore that word\n",
        "\n",
        "  #if length >0\n",
        "  if tokensList:\n",
        "      return pad_sequences([tokensList],maxlen=maxLen, padding='post') #return a padded sequence\n",
        "  \n",
        "  # or return None \n",
        "  return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RMisap9Jqxj"
      },
      "source": [
        "#Preparing ENG-RUS data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O_rD8z0Jpd5",
        "outputId": "043c738b-5269-44c6-fdb3-322ec69ced53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input phrase example               : Head east. \n",
            "Input coded phrase example         : [1982 7518    0    0    0    0    0] \n",
            "Shape of coded input array         : (100000, 7) \n",
            "Established length of input phrase : 7 \n"
          ]
        }
      ],
      "source": [
        "#transform input date to tokens sequences\n",
        "tokenQuestEng=tokenizer.texts_to_sequences(eng_questions)\n",
        "\n",
        "#get max length\n",
        "maxLenQuestEng=max([len(x) for x in tokenQuestEng])\n",
        "\n",
        "#make the sequences have equal length via padding with zeros\n",
        "paddedQuestEng=pad_sequences(tokenQuestEng, maxlen=maxLenQuestEng, padding='post')\n",
        "\n",
        "#to np.array\n",
        "encEngInput=np.array(paddedQuestEng)\n",
        "\n",
        "ind=1111 #index of example\n",
        "print(\"Input phrase example               : {} \".format(eng_questions[ind]))\n",
        "print('Input coded phrase example         : {} '.format(encEngInput[ind]))\n",
        "print('Shape of coded input array         : {} '.format(encEngInput.shape))\n",
        "print('Established length of input phrase : {} '.format(maxLenQuestEng))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZjsVMWGMuS4"
      },
      "source": [
        "training data prepocessing for decoder input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uUs_CX-MzNi",
        "outputId": "b5edbe02-aced-4baf-90cf-8cc84d8c5974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder input phrase example                   : <START> Направляйтесь на восток. <END> \n",
            "Decoder input coded phrase example             : [    1 12131    38  7867     2     0     0     0     0     0     0     0\n",
            "     0] \n",
            "Shape of coded input array for decoder         : (100000, 13) \n",
            "Established length of input phrase for decoder : 13 \n"
          ]
        }
      ],
      "source": [
        "tokenAnsRus=tokenizer.texts_to_sequences(rus_answers)\n",
        "maxLenAnsRus=max([len(x) for x in tokenAnsRus])\n",
        "\n",
        "paddedAnsRus=pad_sequences(tokenAnsRus, maxlen=maxLenAnsRus, padding='post')\n",
        "\n",
        "decRusInput=np.array(paddedAnsRus)\n",
        "\n",
        "ind=1111 #index of example\n",
        "print(\"Decoder input phrase example                   : {} \".format(rus_answers[ind]))\n",
        "print('Decoder input coded phrase example             : {} '.format(decRusInput[ind]))\n",
        "print('Shape of coded input array for decoder         : {} '.format(decRusInput.shape))\n",
        "print('Established length of input phrase for decoder : {} '.format(maxLenAnsRus))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LVxTyqiOQ9t"
      },
      "source": [
        "Validation data preprocessing for decoder output (these data are equal to data above, except deleted //'START' tag "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsgpWHYzOQe8",
        "outputId": "50201469-71c0-4d79-f0a0-b8ecca8db12a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder output phrase example                   : <START> Направляйтесь на восток. <END> \n",
            "Decoder output coded phrase example             : [12131    38  7867     2     0     0     0     0     0     0     0     0\n",
            "     0] \n",
            "Shape of coded output array for decoder         : (100000, 13) \n"
          ]
        }
      ],
      "source": [
        "for i in range(len(tokenAnsRus)):  #remove the <START> tag\n",
        "  tokenAnsRus[i]=tokenAnsRus[i][1:]\n",
        "\n",
        "#make actions which are equal to action in previous code block\n",
        "\n",
        "#emphasise that we use max length  of phrase from previous block to train the model properly \n",
        "paddedAnsRus=pad_sequences(tokenAnsRus, maxlen=maxLenAnsRus, padding='post')  \n",
        "\n",
        "decRusOutput=np.array(paddedAnsRus)\n",
        "\n",
        "ind=1111 #index of example\n",
        "print(\"Decoder output phrase example                   : {} \".format(rus_answers[ind]))\n",
        "print('Decoder output coded phrase example             : {} '.format(decRusOutput[ind]))\n",
        "print('Shape of coded output array for decoder         : {} '.format(decRusOutput.shape))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaW8i4tZQoOS"
      },
      "source": [
        "#Preparing RUS-ENG data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n40EdhlLQs4_",
        "outputId": "f4f57b38-387f-4ad2-dedb-7827f6313178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input phrase example               : Направляйтесь на восток. \n",
            "Input coded phrase example         : [12131    38  7867     0     0     0     0     0     0     0     0] \n",
            "Shape of coded input array         : (100000, 11) \n",
            "Established length of input phrase : 11 \n"
          ]
        }
      ],
      "source": [
        "#transform input date to tokens sequences\n",
        "tokenQuestRus=tokenizer.texts_to_sequences(rus_questions)\n",
        "\n",
        "#get max length\n",
        "maxLenQuestRus=max([len(x) for x in tokenQuestRus])\n",
        "\n",
        "#make the sequences have equal length via padding with zeros\n",
        "paddedQuestRus=pad_sequences(tokenQuestRus, maxlen=maxLenQuestRus, padding='post')\n",
        "\n",
        "#to np.array\n",
        "encRusInput=np.array(paddedQuestRus)\n",
        "\n",
        "ind=1111 #index of example\n",
        "print(\"Input phrase example               : {} \".format(rus_questions[ind]))\n",
        "print('Input coded phrase example         : {} '.format(encRusInput[ind]))\n",
        "print('Shape of coded input array         : {} '.format(encRusInput.shape))\n",
        "print('Established length of input phrase : {} '.format(maxLenQuestRus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfyysHa3YQKm",
        "outputId": "7bd9af53-15ae-4aff-8c39-d406b4a5a0bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder input phrase example                   : <START> Head east. <END> \n",
            "Decoder input coded phrase example             : [   1 1982 7518    2    0    0    0    0    0] \n",
            "Shape of coded input array for decoder         : (100000, 9) \n",
            "Established length of input phrase for decoder : 9 \n"
          ]
        }
      ],
      "source": [
        "tokenAnsEng=tokenizer.texts_to_sequences(eng_answers)\n",
        "maxLenAnsEng=max([len(x) for x in tokenAnsEng])\n",
        "\n",
        "paddedAnsEng=pad_sequences(tokenAnsEng, maxlen=maxLenAnsEng, padding='post')\n",
        "\n",
        "decEngInput=np.array(paddedAnsEng)\n",
        "\n",
        "ind=1111 #index of example\n",
        "print(\"Decoder input phrase example                   : {} \".format(eng_answers[ind]))\n",
        "print('Decoder input coded phrase example             : {} '.format(decEngInput[ind]))\n",
        "print('Shape of coded input array for decoder         : {} '.format(decEngInput.shape))\n",
        "print('Established length of input phrase for decoder : {} '.format(maxLenAnsEng))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl490Q4MYxpH",
        "outputId": "deb542f3-0094-4468-bc46-f96fa22e5a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder output phrase example                   : <START> Head east. <END> \n",
            "Decoder output coded phrase example             : [1982 7518    2    0    0    0    0    0    0] \n",
            "Shape of coded output array for decoder         : (100000, 9) \n"
          ]
        }
      ],
      "source": [
        "for i in range(len(tokenAnsEng)):  #remove the <START> tag\n",
        "  tokenAnsEng[i]=tokenAnsEng[i][1:]\n",
        "\n",
        "#make actions which are equal to action in previous code block\n",
        "\n",
        "#emphasise that we use max length  of phrase from previous block to train the model properly \n",
        "paddedAnsEng=pad_sequences(tokenAnsEng, maxlen=maxLenAnsEng, padding='post')  \n",
        "\n",
        "decEngOutput=np.array(paddedAnsEng)\n",
        "\n",
        "ind=1111 #index of example\n",
        "print(\"Decoder output phrase example                   : {} \".format(eng_answers[ind]))\n",
        "print('Decoder output coded phrase example             : {} '.format(decEngOutput[ind]))\n",
        "print('Shape of coded output array for decoder         : {} '.format(decEngOutput.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzWmTcZwRUQ2"
      },
      "source": [
        "# The Model Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sEKDZkdUQKx"
      },
      "outputs": [],
      "source": [
        "class Translator():\n",
        "  def __init__(self, maxLenInput,maxLenOutput, drop_rate=0.2):\n",
        "    self.num_units=400                # number of neurons\n",
        "    self.maxLenInput=maxLenInput      #maximum length of input sentence\n",
        "    self.maxLenOutput=maxLenOutput    #maximum length of output sentence\n",
        "    self.drop_rate=drop_rate          #dropout rate\n",
        "\n",
        "    self.__makeEncoder()    #create the encoder\n",
        "    self.__makeDecoder()    #create the decoder\n",
        "    \n",
        "    self.modelTrain=Model([self.encInput,self.decInput],self.output)  #create the model\n",
        "    self.modelTrain.compile(optimizer=RMSprop(), loss='sparse_categorical_crossentropy') #compile the model \n",
        "    \n",
        "  #encoder architecture\n",
        "  def __makeEncoder(self):\n",
        "    self.encInput=Input(shape=(None,))                                           #input layer\n",
        "    encEmb=Embedding(vocabularySize,self.num_units, mask_zero=True) (self.encInput)    #embedding layer\n",
        "    drop=SpatialDropout1D(self.drop_rate) (encEmb)\n",
        "    outputs, state_h, state_c=LSTM(self.num_units, return_state=True) (drop)         #LSTM with its states\n",
        "\n",
        "    self.encStates=[state_h, state_c]                                            #encoder states\n",
        "\n",
        "  #decoder architecture\n",
        "  def __makeDecoder(self):\n",
        "\n",
        "    #some layers for decoder\n",
        "    self.decLSTM=LSTM(self.num_units, return_state=True, return_sequences=True)            #LSTM layer with sequences and states\n",
        "    self.decDense=Dense(vocabularySize,activation='softmax')                    #Dense with softmax activation\n",
        "\n",
        "    self.decInput=Input(shape=(None,))                                          #input layer\n",
        "    self.decEmb=Embedding(vocabularySize,self.num_units, mask_zero=True) (self.decInput)   #embedding\n",
        "    drop=SpatialDropout1D(self.drop_rate) (self.decEmb)\n",
        "    decoderOutputs, _, _ =self.decLSTM(drop,initial_state=self.encStates) #LSTM outputs\n",
        "    self.output=self.decDense(decoderOutputs)\n",
        "\n",
        "\n",
        "  #train function \n",
        "  def train(self,xDataInput,yDataInput,batch_size=256,epochs=30,initial_epoch=0, val_split=0.1, random_seed=33 ):\n",
        "    \n",
        "    #copy data to independent shuffle\n",
        "    xData1=np.copy(xDataInput[0])\n",
        "    xData2=np.copy(xDataInput[1])\n",
        "    yData=np.copy(yDataInput)\n",
        "    #shuffle with certain seed\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(xData1)\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(xData2)\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(yData)\n",
        "    \n",
        "    history=self.modelTrain.fit([xData1,xData2],yData,batch_size=batch_size,epochs=epochs+initial_epoch,initial_epoch=initial_epoch,validation_split=val_split)\n",
        "\n",
        "    return history.history  #return the history\n",
        "\n",
        "\n",
        "  #method to making inference model\n",
        "  def makeInferenceModel(self):\n",
        "\n",
        "    self.encInfer=Model(self.encInput, self.encStates)\n",
        "\n",
        "    decStateInput_h=Input(shape=(self.num_units,)) #Input for state_h\n",
        "    decStateInput_c=Input(shape=(self.num_units,)) #Input for state_c\n",
        "\n",
        "    decStatesInputs=[decStateInput_h, decStateInput_c] #combine inputs\n",
        "\n",
        "    #get the output from decoder\n",
        "    decOut, state_h, state_c=self.decLSTM(self.decEmb, initial_state=decStatesInputs)\n",
        "\n",
        "    #combine states\n",
        "    decStates=[state_h,state_c]\n",
        "\n",
        "    #fed Dense layer \n",
        "    decOut=self.decDense(decOut)\n",
        "\n",
        "    self.decInf=Model([self.decInput]+decStatesInputs,[decOut]+decStates)\n",
        "  \n",
        "\n",
        "  #Translation of sentence\n",
        "  def translate(self,inputs):\n",
        "    \n",
        "    in_tokens=strToTokens(inputs,self.maxLenInput) #get tokens from input sentence\n",
        "\n",
        "    if in_tokens is None: #if network don't know every word from input\n",
        "      return 'None'\n",
        "\n",
        "    oneTargetToken=np.zeros((1,1))  #one token to feed the decoder\n",
        "    oneTargetToken[0,0]=tokenizer.word_index['start'] #firstly it's tag \"start\"\n",
        "\n",
        "    stopCondition=False\n",
        "\n",
        "    outputs=''  #decoded translation\n",
        "\n",
        "    statesValues=self.encInfer(in_tokens) #get the encoder station\n",
        "\n",
        "    while not stopCondition:\n",
        "      \n",
        "      #make prediction\n",
        "      decOut, h, c=self.decInf.predict([oneTargetToken]+statesValues)\n",
        "\n",
        "      #get the token of predicted word\n",
        "      sampledWordInd=np.argmax(decOut[0,0,:])\n",
        "\n",
        "      sampledWord = None #variable for word in natural language\n",
        "\n",
        "      #find the target token\n",
        "      for word, index in tokenizer.word_index.items():\n",
        "        if sampledWordInd==index:\n",
        "            outputs+=' {}'.format(word)\n",
        "            sampledWord=word\n",
        "\n",
        "      #tag \"end\" was generated or length is more than maximum length\n",
        "      if sampledWord=='end' or len(outputs.split(\" \"))>self.maxLenOutput:\n",
        "          stopCondition=True\n",
        "          if sampledWord=='end': #tag 'end' was gotten\n",
        "            outputs=outputs[:-3] #delete the tag\n",
        "\n",
        "      oneTargetToken[0,0]=sampledWordInd #update the token to feed\n",
        "\n",
        "      statesValues=[h,c] #update the states values\n",
        "    \n",
        "    outputs=outputs[1:] #delete the first \" \"\n",
        "\n",
        "    if outputs[-1]==\" \": #delete the last \" \", if it exists\n",
        "      outputs=outputs[:-1]\n",
        "\n",
        "    return outputs\n",
        "\n",
        "  #saving and loading weights\n",
        "  def saveWeights(self,path):\n",
        "    self.modelTrain.save_weights(path)\n",
        "\n",
        "  def loadWeights(self,path):\n",
        "    self.modelTrain.load_weights(path)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8bFFeqe7dBn"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNICI1eLCLFO"
      },
      "source": [
        "##ENG-RUS translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsZILmMIAesv"
      },
      "outputs": [],
      "source": [
        "EngRusTranslator=Translator(maxLenQuestEng,maxLenAnsRus, drop_rate=0.4) #creating the ENG-RUS translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lA_1mpoW7g07",
        "outputId": "2b1cc358-a8bb-4704-9364-5012e5a5643a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "352/352 [==============================] - 115s 301ms/step - loss: 1.7962 - val_loss: 1.5058\n",
            "Epoch 2/100\n",
            "352/352 [==============================] - 103s 292ms/step - loss: 1.3672 - val_loss: 1.2940\n",
            "Epoch 3/100\n",
            "352/352 [==============================] - 103s 292ms/step - loss: 1.1795 - val_loss: 1.1528\n",
            "Epoch 4/100\n",
            "352/352 [==============================] - 103s 292ms/step - loss: 1.0474 - val_loss: 1.0552\n",
            "Epoch 5/100\n",
            "352/352 [==============================] - 103s 292ms/step - loss: 0.9482 - val_loss: 0.9878\n",
            "Epoch 6/100\n",
            "352/352 [==============================] - 103s 292ms/step - loss: 0.8759 - val_loss: 0.9407\n",
            "Epoch 7/100\n",
            "352/352 [==============================] - 103s 292ms/step - loss: 0.8193 - val_loss: 0.9036\n",
            "Epoch 8/100\n",
            "352/352 [==============================] - 103s 292ms/step - loss: 0.7701 - val_loss: 0.8754\n",
            "Epoch 9/100\n",
            "352/352 [==============================] - 103s 292ms/step - loss: 0.7311 - val_loss: 0.8575\n",
            "Epoch 10/100\n",
            "352/352 [==============================] - 103s 291ms/step - loss: 0.6997 - val_loss: 0.8451\n",
            "Epoch 11/100\n",
            "352/352 [==============================] - 103s 291ms/step - loss: 0.6745 - val_loss: 0.8330\n",
            "Epoch 12/100\n",
            "352/352 [==============================] - 102s 291ms/step - loss: 0.6495 - val_loss: 0.8167\n",
            "Epoch 13/100\n",
            "352/352 [==============================] - 102s 290ms/step - loss: 0.6294 - val_loss: 0.8107\n",
            "Epoch 14/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.6134 - val_loss: 0.8046\n",
            "Epoch 15/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.5976 - val_loss: 0.8001\n",
            "Epoch 16/100\n",
            "352/352 [==============================] - 102s 290ms/step - loss: 0.5819 - val_loss: 0.7910\n",
            "Epoch 17/100\n",
            "352/352 [==============================] - 102s 290ms/step - loss: 0.5669 - val_loss: 0.7917\n",
            "Epoch 18/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.5559 - val_loss: 0.7877\n",
            "Epoch 19/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.5427 - val_loss: 0.7889\n",
            "Epoch 20/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.5336 - val_loss: 0.7854\n",
            "Epoch 21/100\n",
            "352/352 [==============================] - 102s 290ms/step - loss: 0.5249 - val_loss: 0.7861\n",
            "Epoch 22/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.5167 - val_loss: 0.7887\n",
            "Epoch 23/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.5080 - val_loss: 0.7871\n",
            "Epoch 24/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.5000 - val_loss: 0.7864\n",
            "Epoch 25/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.4917 - val_loss: 0.7860\n",
            "Epoch 26/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.4829 - val_loss: 0.7819\n",
            "Epoch 27/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.4751 - val_loss: 0.7794\n",
            "Epoch 28/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.4678 - val_loss: 0.7795\n",
            "Epoch 29/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.4621 - val_loss: 0.7784\n",
            "Epoch 30/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.4565 - val_loss: 0.7774\n",
            "Epoch 31/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.4507 - val_loss: 0.7777\n",
            "Epoch 32/100\n",
            "352/352 [==============================] - 102s 290ms/step - loss: 0.4451 - val_loss: 0.7769\n",
            "Epoch 33/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.4400 - val_loss: 0.7774\n",
            "Epoch 34/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.4349 - val_loss: 0.7766\n",
            "Epoch 35/100\n",
            "352/352 [==============================] - 102s 290ms/step - loss: 0.4295 - val_loss: 0.7760\n",
            "Epoch 36/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.4245 - val_loss: 0.7747\n",
            "Epoch 37/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.4193 - val_loss: 0.7723\n",
            "Epoch 38/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.4149 - val_loss: 0.7710\n",
            "Epoch 39/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.4101 - val_loss: 0.7714\n",
            "Epoch 40/100\n",
            "352/352 [==============================] - 103s 292ms/step - loss: 0.4059 - val_loss: 0.7718\n",
            "Epoch 41/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.4019 - val_loss: 0.7716\n",
            "Epoch 42/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3979 - val_loss: 0.7710\n",
            "Epoch 43/100\n",
            "352/352 [==============================] - 102s 290ms/step - loss: 0.3943 - val_loss: 0.7674\n",
            "Epoch 44/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3905 - val_loss: 0.7716\n",
            "Epoch 45/100\n",
            "352/352 [==============================] - 102s 290ms/step - loss: 0.3869 - val_loss: 0.7690\n",
            "Epoch 46/100\n",
            "352/352 [==============================] - 102s 290ms/step - loss: 0.3837 - val_loss: 0.7681\n",
            "Epoch 47/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3806 - val_loss: 0.7705\n",
            "Epoch 48/100\n",
            "352/352 [==============================] - 102s 290ms/step - loss: 0.3774 - val_loss: 0.7674\n",
            "Epoch 49/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3747 - val_loss: 0.7679\n",
            "Epoch 50/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3720 - val_loss: 0.7662\n",
            "Epoch 51/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3697 - val_loss: 0.7685\n",
            "Epoch 52/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3678 - val_loss: 0.7684\n",
            "Epoch 53/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3652 - val_loss: 0.7689\n",
            "Epoch 54/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3631 - val_loss: 0.7708\n",
            "Epoch 55/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3614 - val_loss: 0.7711\n",
            "Epoch 56/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3595 - val_loss: 0.7722\n",
            "Epoch 57/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3578 - val_loss: 0.7719\n",
            "Epoch 58/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3565 - val_loss: 0.7733\n",
            "Epoch 59/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3548 - val_loss: 0.7737\n",
            "Epoch 60/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3534 - val_loss: 0.7748\n",
            "Epoch 61/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3525 - val_loss: 0.7748\n",
            "Epoch 62/100\n",
            "352/352 [==============================] - 102s 290ms/step - loss: 0.3515 - val_loss: 0.7758\n",
            "Epoch 63/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3503 - val_loss: 0.7765\n",
            "Epoch 64/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3490 - val_loss: 0.7793\n",
            "Epoch 65/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3482 - val_loss: 0.7785\n",
            "Epoch 66/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3474 - val_loss: 0.7786\n",
            "Epoch 67/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3464 - val_loss: 0.7801\n",
            "Epoch 68/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3457 - val_loss: 0.7826\n",
            "Epoch 69/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3448 - val_loss: 0.7825\n",
            "Epoch 70/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3440 - val_loss: 0.7841\n",
            "Epoch 71/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3425 - val_loss: 0.7832\n",
            "Epoch 72/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3417 - val_loss: 0.7855\n",
            "Epoch 73/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3410 - val_loss: 0.7839\n",
            "Epoch 74/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3399 - val_loss: 0.7867\n",
            "Epoch 75/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3389 - val_loss: 0.7868\n",
            "Epoch 76/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3376 - val_loss: 0.7872\n",
            "Epoch 77/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3363 - val_loss: 0.7869\n",
            "Epoch 78/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3354 - val_loss: 0.7905\n",
            "Epoch 79/100\n",
            "352/352 [==============================] - 102s 289ms/step - loss: 0.3343 - val_loss: 0.7898\n",
            "Epoch 80/100\n",
            "213/352 [=================>............] - ETA: 38s - loss: 0.3222"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-2c9d375110a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#fitting the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEngRusTranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencEngInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecRusInput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecRusOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-19e64c1405b9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, xDataInput, yDataInput, batch_size, epochs, initial_epoch, val_split, random_seed)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxData1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxData2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m  \u001b[0;31m#return the history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#fitting the model\n",
        "history=EngRusTranslator.train([encEngInput,decRusInput],decRusOutput,epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stop the training process due to overfitting"
      ],
      "metadata": {
        "id": "cITSR6t01AU8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T17CPSL9-AYw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "676beb02-e416-444c-c550-596e8581f32d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#plot the chart of loss-function\n",
        "plt.plot(history['loss'],label='train')\n",
        "plt.plot(history['val_loss'],label='val')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('ENG-RUS Translator Training')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mAbd5oU-h3t"
      },
      "outputs": [],
      "source": [
        "EngRusTranslator.makeInferenceModel() #creating the inference model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oX0L_9JqE_mw"
      },
      "outputs": [],
      "source": [
        "EngRusTranslator.saveWeights('/content/drive/MyDrive/PostUAI/advancedSeq2Seq/EngRusDrop04U400.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1e-aGCqFiOL"
      },
      "outputs": [],
      "source": [
        "EngRusTranslator.loadWeights('/content/drive/MyDrive/PostUAI/advancedSeq2Seq/EngRusDrop04U400.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bUMOUDnt-rpv",
        "outputId": "f4970491-6afa-4d36-dee1-e8ff445921dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'что вы делаете?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "EngRusTranslator.translate('What are you doing?') #translation example "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "odfFEpuZl8Jt",
        "outputId": "2ce1c2be-6e2c-4d4b-d0e5-6595f9457b87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'позволь мне мою руку.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "EngRusTranslator.translate('Hello, my friend.') #translation example "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9JZiH-i3mDNN",
        "outputId": "f64dacef-8a0d-4185-f8ee-d0345657ff94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'рада тебя видеть.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "EngRusTranslator.translate(\"I'm glad to see you.\") #translation example "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vjNEeA4RmVsU",
        "outputId": "c81d8001-5901-4763-a3bf-5bc4fe98d1a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'у меня машина не работу.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "EngRusTranslator.translate(\"My car does not work.\") #translation example "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bFlLFXVznQei",
        "outputId": "80aa7b04-357b-4fb9-e6cb-eef1d3ebfd5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'я устала.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "EngRusTranslator.translate(\"I'm tired.\") #translation example "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "roKcIEyonXc6",
        "outputId": "ec3153c3-c360-4547-a372-6a7928582ef6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'что это вас в своей лестнице.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "EngRusTranslator.translate(\"What is your name?.\") #translation example "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XXXNECkCuml"
      },
      "source": [
        "##RUS-ENG Translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1y4bF-PmwNR"
      },
      "outputs": [],
      "source": [
        "RusEngTranslator=Translator(maxLenQuestRus,maxLenAnsEng, drop_rate=0.4) #creating the ENG-RUS translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_lJRz0OC0_E",
        "outputId": "ec63face-bc0c-4afa-eef8-68946943562e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "352/352 [==============================] - 98s 239ms/step - loss: 2.4199 - val_loss: 1.9181\n",
            "Epoch 2/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 1.6938 - val_loss: 1.5271\n",
            "Epoch 3/100\n",
            "352/352 [==============================] - 83s 235ms/step - loss: 1.3870 - val_loss: 1.3109\n",
            "Epoch 4/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 1.1820 - val_loss: 1.1578\n",
            "Epoch 5/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 1.0244 - val_loss: 1.0531\n",
            "Epoch 6/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.9017 - val_loss: 0.9677\n",
            "Epoch 7/100\n",
            "352/352 [==============================] - 80s 229ms/step - loss: 0.8048 - val_loss: 0.8994\n",
            "Epoch 8/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.7246 - val_loss: 0.8562\n",
            "Epoch 9/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 0.6587 - val_loss: 0.8141\n",
            "Epoch 10/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.6035 - val_loss: 0.7833\n",
            "Epoch 11/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.5578 - val_loss: 0.7642\n",
            "Epoch 12/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.5188 - val_loss: 0.7453\n",
            "Epoch 13/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.4845 - val_loss: 0.7269\n",
            "Epoch 14/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.4549 - val_loss: 0.7178\n",
            "Epoch 15/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.4313 - val_loss: 0.7093\n",
            "Epoch 16/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.4083 - val_loss: 0.6992\n",
            "Epoch 17/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.3869 - val_loss: 0.6906\n",
            "Epoch 18/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.3681 - val_loss: 0.6850\n",
            "Epoch 19/100\n",
            "352/352 [==============================] - 80s 228ms/step - loss: 0.3506 - val_loss: 0.6817\n",
            "Epoch 20/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.3366 - val_loss: 0.6804\n",
            "Epoch 21/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.3251 - val_loss: 0.6772\n",
            "Epoch 22/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.3134 - val_loss: 0.6775\n",
            "Epoch 23/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.3031 - val_loss: 0.6752\n",
            "Epoch 24/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.2935 - val_loss: 0.6737\n",
            "Epoch 25/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.2843 - val_loss: 0.6700\n",
            "Epoch 26/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.2755 - val_loss: 0.6693\n",
            "Epoch 27/100\n",
            "352/352 [==============================] - 80s 228ms/step - loss: 0.2674 - val_loss: 0.6691\n",
            "Epoch 28/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.2604 - val_loss: 0.6676\n",
            "Epoch 29/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.2543 - val_loss: 0.6680\n",
            "Epoch 30/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.2474 - val_loss: 0.6681\n",
            "Epoch 31/100\n",
            "352/352 [==============================] - 80s 229ms/step - loss: 0.2411 - val_loss: 0.6674\n",
            "Epoch 32/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.2359 - val_loss: 0.6675\n",
            "Epoch 33/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.2306 - val_loss: 0.6671\n",
            "Epoch 34/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.2252 - val_loss: 0.6659\n",
            "Epoch 35/100\n",
            "352/352 [==============================] - 80s 229ms/step - loss: 0.2202 - val_loss: 0.6657\n",
            "Epoch 36/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.2156 - val_loss: 0.6641\n",
            "Epoch 37/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.2110 - val_loss: 0.6643\n",
            "Epoch 38/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.2065 - val_loss: 0.6645\n",
            "Epoch 39/100\n",
            "352/352 [==============================] - 80s 229ms/step - loss: 0.1995 - val_loss: 0.6627\n",
            "Epoch 40/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.1952 - val_loss: 0.6622\n",
            "Epoch 41/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.1926 - val_loss: 0.6638\n",
            "Epoch 42/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.1893 - val_loss: 0.6654\n",
            "Epoch 43/100\n",
            "352/352 [==============================] - 80s 228ms/step - loss: 0.1863 - val_loss: 0.6625\n",
            "Epoch 44/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.1837 - val_loss: 0.6664\n",
            "Epoch 45/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.1805 - val_loss: 0.6663\n",
            "Epoch 46/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.1784 - val_loss: 0.6677\n",
            "Epoch 47/100\n",
            "352/352 [==============================] - 80s 228ms/step - loss: 0.1760 - val_loss: 0.6684\n",
            "Epoch 48/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.1740 - val_loss: 0.6669\n",
            "Epoch 49/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.1722 - val_loss: 0.6677\n",
            "Epoch 50/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.1700 - val_loss: 0.6662\n",
            "Epoch 51/100\n",
            "352/352 [==============================] - 80s 228ms/step - loss: 0.1685 - val_loss: 0.6656\n",
            "Epoch 52/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.1660 - val_loss: 0.6645\n",
            "Epoch 53/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.1641 - val_loss: 0.6647\n",
            "Epoch 54/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.1624 - val_loss: 0.6680\n",
            "Epoch 55/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.1612 - val_loss: 0.6687\n",
            "Epoch 56/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.1592 - val_loss: 0.6655\n",
            "Epoch 57/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.1571 - val_loss: 0.6676\n",
            "Epoch 58/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.1552 - val_loss: 0.6674\n",
            "Epoch 59/100\n",
            "352/352 [==============================] - 80s 228ms/step - loss: 0.1531 - val_loss: 0.6647\n",
            "Epoch 60/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.1508 - val_loss: 0.6656\n",
            "Epoch 61/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.1494 - val_loss: 0.6685\n",
            "Epoch 62/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.1474 - val_loss: 0.6641\n",
            "Epoch 63/100\n",
            "352/352 [==============================] - 80s 228ms/step - loss: 0.1459 - val_loss: 0.6634\n",
            "Epoch 64/100\n",
            "352/352 [==============================] - 80s 229ms/step - loss: 0.1438 - val_loss: 0.6644\n",
            "Epoch 65/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.1425 - val_loss: 0.6654\n",
            "Epoch 66/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.1406 - val_loss: 0.6643\n",
            "Epoch 67/100\n",
            "352/352 [==============================] - 80s 228ms/step - loss: 0.1388 - val_loss: 0.6641\n",
            "Epoch 68/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.1376 - val_loss: 0.6632\n",
            "Epoch 69/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 0.1358 - val_loss: 0.6650\n",
            "Epoch 70/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 0.1341 - val_loss: 0.6652\n",
            "Epoch 71/100\n",
            "352/352 [==============================] - 81s 229ms/step - loss: 0.1328 - val_loss: 0.6669\n",
            "Epoch 72/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 0.1312 - val_loss: 0.6673\n",
            "Epoch 73/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 0.1301 - val_loss: 0.6670\n",
            "Epoch 74/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 0.1290 - val_loss: 0.6665\n",
            "Epoch 75/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.1277 - val_loss: 0.6666\n",
            "Epoch 76/100\n",
            "352/352 [==============================] - 82s 232ms/step - loss: 0.1261 - val_loss: 0.6677\n",
            "Epoch 77/100\n",
            "352/352 [==============================] - 82s 232ms/step - loss: 0.1250 - val_loss: 0.6661\n",
            "Epoch 78/100\n",
            "352/352 [==============================] - 82s 232ms/step - loss: 0.1239 - val_loss: 0.6674\n",
            "Epoch 79/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 0.1228 - val_loss: 0.6710\n",
            "Epoch 80/100\n",
            "352/352 [==============================] - 82s 232ms/step - loss: 0.1219 - val_loss: 0.6703\n",
            "Epoch 81/100\n",
            "352/352 [==============================] - 82s 232ms/step - loss: 0.1205 - val_loss: 0.6704\n",
            "Epoch 82/100\n",
            "352/352 [==============================] - 82s 232ms/step - loss: 0.1199 - val_loss: 0.6712\n",
            "Epoch 83/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 0.1190 - val_loss: 0.6707\n",
            "Epoch 84/100\n",
            "352/352 [==============================] - 82s 232ms/step - loss: 0.1180 - val_loss: 0.6718\n",
            "Epoch 85/100\n",
            "352/352 [==============================] - 82s 232ms/step - loss: 0.1171 - val_loss: 0.6703\n",
            "Epoch 86/100\n",
            "352/352 [==============================] - 82s 232ms/step - loss: 0.1165 - val_loss: 0.6732\n",
            "Epoch 87/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 0.1156 - val_loss: 0.6732\n",
            "Epoch 88/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 0.1152 - val_loss: 0.6769\n",
            "Epoch 89/100\n",
            "352/352 [==============================] - 82s 232ms/step - loss: 0.1145 - val_loss: 0.6739\n",
            "Epoch 90/100\n",
            "352/352 [==============================] - 82s 232ms/step - loss: 0.1134 - val_loss: 0.6766\n",
            "Epoch 91/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 0.1136 - val_loss: 0.6763\n",
            "Epoch 92/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 0.1130 - val_loss: 0.6756\n",
            "Epoch 93/100\n",
            "352/352 [==============================] - 82s 232ms/step - loss: 0.1124 - val_loss: 0.6788\n",
            "Epoch 94/100\n",
            "352/352 [==============================] - 82s 232ms/step - loss: 0.1125 - val_loss: 0.6795\n",
            "Epoch 95/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 0.1124 - val_loss: 0.6783\n",
            "Epoch 96/100\n",
            "352/352 [==============================] - 82s 232ms/step - loss: 0.1123 - val_loss: 0.6829\n",
            "Epoch 97/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 0.1116 - val_loss: 0.6806\n",
            "Epoch 98/100\n",
            "352/352 [==============================] - 81s 231ms/step - loss: 0.1114 - val_loss: 0.6803\n",
            "Epoch 99/100\n",
            "352/352 [==============================] - 81s 230ms/step - loss: 0.1112 - val_loss: 0.6817\n",
            "Epoch 100/100\n",
            "352/352 [==============================] - 83s 237ms/step - loss: 0.1112 - val_loss: 0.6805\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#fitting the model\n",
        "history=RusEngTranslator.train([encRusInput,decEngInput],decEngOutput,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "AkSUNMy0FpYI",
        "outputId": "d70579a4-6180-40bd-b6b6-5848ecd5bee0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#plot the chart of loss-function\n",
        "plt.plot(history['loss'],label='train')\n",
        "plt.plot(history['val_loss'],label='val')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('ENG-RUS Translator Training')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_4QqsWZFwmj"
      },
      "outputs": [],
      "source": [
        "RusEngTranslator.makeInferenceModel() #creating the inference model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb-RJ2ILI68R"
      },
      "outputs": [],
      "source": [
        "RusEngTranslator.saveWeights('/content/drive/MyDrive/PostUAI/advancedSeq2Seq/RusEngDrop04U400.h5.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UII04cpam0mI"
      },
      "outputs": [],
      "source": [
        "RusEngTranslator.loadWeights('/content/drive/MyDrive/PostUAI/advancedSeq2Seq/RusEngDrop04U400.h5.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Jj7J3rlGF5gR",
        "outputId": "80d2a542-c28f-47d8-faf5-5d1360bb4360"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'how are you?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "RusEngTranslator.translate('Как твои дела?') #translation example "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eWeOk-9Ym7-a",
        "outputId": "9b7ae5b6-8b4c-4523-addb-56ac6c8dc667"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"i'm glad to see you.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "RusEngTranslator.translate('Я рад видеть тебя.') #translation example "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ln4_K4BnnDn_",
        "outputId": "e8b35977-4f94-4271-fc80-96eb9d32bb2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"my car isn't working.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "RusEngTranslator.translate('Моя машина не работает.') #translation example "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "39sXt-I7nK95",
        "outputId": "de266d4f-180c-4e36-f6f8-0b325f15219f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i got tired.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "RusEngTranslator.translate('Я устал.') #translation example "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "x7jHm4Z2nd60",
        "outputId": "f5dc507d-0f21-4448-89e6-0d3403e72dc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what was your name?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "RusEngTranslator.translate('Как тебя зовут?') #translation example "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1IsG-ZkGBuU"
      },
      "source": [
        "#Double Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJLY8Xj-orIl"
      },
      "source": [
        "##ENG-RUS -> RUS-ENG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdFiYqxkGNqH"
      },
      "outputs": [],
      "source": [
        "def EngRus_RusEng(eng_init):\n",
        "  rus=EngRusTranslator.translate(eng_init)\n",
        "  eng=RusEngTranslator.translate(rus)\n",
        "\n",
        "  print('Original english sentence: ', eng_init)\n",
        "  print('Translated russian sentence: ', rus)\n",
        "  print('Double translated english sentence: ', eng)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK8GpGRih0i2",
        "outputId": "b9daab89-44dc-4856-d309-d06233d091c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original english sentence:  How much is it?\n",
            "Translated russian sentence:  сколько это стоит?\n",
            "Double translated english sentence:  how much is it?\n"
          ]
        }
      ],
      "source": [
        "EngRus_RusEng(\"How much is it?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PihAfxTIoNWd",
        "outputId": "f2f3f653-40a8-4385-fd98-94328ebb206b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original english sentence:  Do you speak English?\n",
            "Translated russian sentence:  вы говорите по тебе понравился.\n",
            "Double translated english sentence:  you really missed you.\n"
          ]
        }
      ],
      "source": [
        "EngRus_RusEng(\"Do you speak English?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msAHizgAoXsM",
        "outputId": "037cef1e-4e06-4c23-a73c-f34e7531d296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original english sentence:  I'm tired.\n",
            "Translated russian sentence:  я устала.\n",
            "Double translated english sentence:  i'm tired.\n"
          ]
        }
      ],
      "source": [
        "EngRus_RusEng(\"I'm tired.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGrB-GY-oepe",
        "outputId": "3a42d523-a7f2-4a6e-f6a7-767815835500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original english sentence:  It's rainy today.\n",
            "Translated russian sentence:  сегодня нет там.\n",
            "Double translated english sentence:  it's not there.\n"
          ]
        }
      ],
      "source": [
        "EngRus_RusEng(\"It's rainy today.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2c5MdpRoswa"
      },
      "source": [
        "##RUS-ENG -> ENG-RUS "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vZPVp7LoxN7"
      },
      "outputs": [],
      "source": [
        "def RusEng_EngRus(rus_init):\n",
        "  eng=RusEngTranslator.translate(rus_init)\n",
        "  rus=EngRusTranslator.translate(eng)\n",
        "\n",
        "  print('Original russian sentence: ', rus_init)\n",
        "  print('Translated english sentence: ', eng)\n",
        "  print('Double translated russian sentence: ', rus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfN3zGftpGJE",
        "outputId": "6fe56a4f-cb02-4520-a6df-612a15e3998e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original russian sentence:  Лондон - это столица Великобритании.\n",
            "Translated english sentence:  this is it?\n",
            "Double translated russian sentence:  вот и всё.\n"
          ]
        }
      ],
      "source": [
        "RusEng_EngRus(\"Лондон - это столица Великобритании.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbL5I03XpXKs",
        "outputId": "f1565649-6857-483a-dceb-069c6a735a18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original russian sentence:  Это все на сегодня.\n",
            "Translated english sentence:  that's all for today.\n",
            "Double translated russian sentence:  на сегодня всё.\n"
          ]
        }
      ],
      "source": [
        "RusEng_EngRus(\"Это все на сегодня.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbsIALxBpcfv",
        "outputId": "23418b7a-90bf-483c-8e48-c5e087a4032d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original russian sentence:  Сколько вам лет?\n",
            "Translated english sentence:  how old are you?\n",
            "Double translated russian sentence:  сколько вам лет?\n"
          ]
        }
      ],
      "source": [
        "RusEng_EngRus(\"Сколько вам лет?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9m6c0mRpju8",
        "outputId": "67ef560e-535a-4756-a322-a5229c3c75f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original russian sentence:  Вам помочь?\n",
            "Translated english sentence:  shall i help you?\n",
            "Double translated russian sentence:  тебе помочь?\n"
          ]
        }
      ],
      "source": [
        "RusEng_EngRus(\"Вам помочь?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g48Of-9ypp9i",
        "outputId": "4efb6494-7fd3-4c73-e90f-dd1a2a147e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original russian sentence:  Как пройти в библиотеку?\n",
            "Translated english sentence:  how was paid in a lot.\n",
            "Double translated russian sentence:  как прошла в школе была позвоните мне.\n"
          ]
        }
      ],
      "source": [
        "RusEng_EngRus(\"Как пройти в библиотеку?\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6RMisap9Jqxj",
        "oaW8i4tZQoOS"
      ],
      "name": "Seq2Seq Double Translator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}